{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite: weights and architecture of a pre-trained AE.\n",
    "\n",
    "This Notebook builds the quasi-isometric embedding of a local chart of the torus (latent space) into $\\mathbb{R}^3$ using a pyTorch optimizer.\n",
    "\n",
    "Content:\n",
    "1) Data loading. Weights of the AE and encoded latent space data are loaded\n",
    "2) Constructing grid and triangulation.\n",
    "3) Geodesic distances computation via Schauder basis approximation (or loading) + Embedded grid plotting in 3d. 4) Optimization loop. Embedding is constructed via optimization.\n",
    "4) Plotting the embedded grid with trimesh. Saving the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch, yaml\n",
    "import numpy as np\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "violent_saving = False\n",
    "pretrained_AE_setting_name = 'MNIST_Setting_3'\n",
    "Path_AE_config = f'../experiments/{pretrained_AE_setting_name}_config.yaml'\n",
    "\n",
    "with open(Path_AE_config, 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "Path_pictures = f'../experiments/{pretrained_AE_setting_name}'\n",
    "print(\"pictures will be saved at\", Path_pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the pretrained AE + creating directory for results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print(\"Experiment results loaded successfully.\")\n",
    "# Loading data\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "validation_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=100)\n",
    "print(\"Data loaders created successfully.\")\n",
    "\n",
    "# Loading the pre-tained AE\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config)\n",
    "print(\"AE weights loaded successfully.\")\n",
    "print(\"AE weights loaded from\", Path_ae_weights)\n",
    "torus_ae.cpu()\n",
    "torus_ae.eval()\n",
    "print(\"AE sent to cpu and eval mode activated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yaml_config[\"training_mode\"][\"compute_curvature\"] is True:\n",
    "    lambda_curv = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "else:\n",
    "    lambda_curv = 0.\n",
    "print(\"This experiment uses curvature loss weight\", lambda_curv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ricci_regularization.point_plot(encoder=torus_ae.encoder_to_lifting,data_loader=test_loader, show_title=False, config=yaml_config, batch_idx=0)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Constructing grid and triangulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the grid of points \n",
    "num_points = 10\n",
    "\n",
    "x_left = -2#-torch.pi#-torch.pi #-2.0\n",
    "y_bottom = -2#-torch.pi#-torch.pi #-2.0\n",
    "\n",
    "x_size = -x_left*2#2*torch.pi # 4.\n",
    "\n",
    "y_size = -y_bottom*2#2*torch.pi #4. # max shift of geodesics \n",
    "\n",
    "x_right = x_left + x_size\n",
    "y_top = y_bottom + y_size\n",
    "\n",
    "start_points_horizontal = torch.cat([torch.tensor([x_left,y_bottom + k]) for k in torch.linspace(0,y_size,num_points) ]).reshape(num_points,2)\n",
    "\n",
    "horizontal_step = torch.tensor([x_size/(num_points-1),0])\n",
    "grid = torch.cat([(start_points_horizontal + k * horizontal_step) for k in range(num_points)])\n",
    "grid = grid.reshape(num_points,num_points,2)\n",
    "\n",
    "# Triangulate parameter space to determine the triangles using the starting flat grid\n",
    "u = np.linspace(x_left, x_right , endpoint=True, num=num_points)\n",
    "v = np.linspace(y_bottom, y_top , endpoint=True, num=num_points)\n",
    "u, v = np.meshgrid(u, v)\n",
    "u, v = u.flatten(), v.flatten()\n",
    "\n",
    "# Triangulate parameter space to determine the triangles\n",
    "tri = mtri.Triangulation(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Geodesic distances computation via Schauder (or loading) + Grid plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 7 # depth of Schauder basis\n",
    "step_count = 100 # number of interpolation points on each geodesic\n",
    "geodesic_solver = ricci_regularization.Schauder.NumericalGeodesics(n_max, step_count)\n",
    "optimization_device = \"cuda\"\n",
    "num_geodesic_optimization_epochs = 200\n",
    "learning_rate = 0.01\n",
    "torus_ae.to(optimization_device)\n",
    "optimizer_info = {\n",
    "    \"name\": \"Adam\",   # optimizer class name as string\n",
    "    \"args\": {\n",
    "        \"lr\": learning_rate    # learning rate\n",
    "        # \"betas\": (0.9, 0.999)  # optional for Adam\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geodesics are computed minimizing \"energy\" of the curves in the latent space,\n",
    "# No need to compute explicitly the pull-back metric, and thus the algorithm is fast\n",
    "# Computing horizontal small geodesics\n",
    "left_points_on_horizontal_segments = grid[:-1,:,:].reshape(-1,2)\n",
    "right_points_on_horizontal_segments = grid[1:,:,:].reshape(-1,2)\n",
    "bottom_points_on_horizontal_segments = grid[:,:-1,:].reshape(-1,2)\n",
    "top_points_on_horizontal_segments = grid[:,1:,:].reshape(-1,2)\n",
    "\n",
    "_, horizontal_geodesics_connecting_grid_nodes = geodesic_solver.computeGeodesicInterpolationBatch(\n",
    "                                            generator=torus_ae.decoder_torus, \n",
    "                                            optimizer_info=optimizer_info,\n",
    "                                            m1_batch=left_points_on_horizontal_segments,\n",
    "                                            m2_batch=right_points_on_horizontal_segments, \n",
    "                                            epochs=num_geodesic_optimization_epochs,\n",
    "                                            display_info=\"horizontal geodesic optimization\",\n",
    "                                            device=optimization_device)\n",
    "\n",
    "_, vertical_geodesics_connecting_grid_nodes = geodesic_solver.computeGeodesicInterpolationBatch(\n",
    "                                            generator=torus_ae.decoder_torus, \n",
    "                                            optimizer_info=optimizer_info,\n",
    "                                            m1_batch=bottom_points_on_horizontal_segments,\n",
    "                                            m2_batch=top_points_on_horizontal_segments, \n",
    "                                            epochs=num_geodesic_optimization_epochs,\n",
    "                                            display_info=\"vertical geodesic optimization\",\n",
    "                                            device=optimization_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_geodesics_connecting_grid_nodes = horizontal_geodesics_connecting_grid_nodes.to(optimization_device)\n",
    "horizontal_lengths = ricci_regularization.RiemannianKmeansTools.compute_lengths(curve=horizontal_geodesics_connecting_grid_nodes,\n",
    "                                                           decoder=torus_ae.decoder_torus)\n",
    "\n",
    "vertical_geodesics_connecting_grid_nodes = vertical_geodesics_connecting_grid_nodes.to(optimization_device)\n",
    "vertical_lengths = ricci_regularization.RiemannianKmeansTools.compute_lengths(curve=vertical_geodesics_connecting_grid_nodes,\n",
    "                                                           decoder=torus_ae.decoder_torus)\n",
    "\n",
    "torch.save(horizontal_lengths,Path_pictures+'/horizontal_lengths.pt')\n",
    "torch.save(vertical_lengths,Path_pictures+'/vertical_lengths.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_lengths**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_energies = ricci_regularization.RiemannianKmeansTools.compute_energy(curve=horizontal_geodesics_connecting_grid_nodes,\n",
    "                                                           decoder=torus_ae.decoder_torus, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial embedding rect shape\n",
    "with torch.no_grad():\n",
    "    horizontal_lengths_reshaped = horizontal_lengths.reshape(num_points-1,num_points)\n",
    "    vertical_lengths_reshaped = vertical_lengths.reshape(num_points,num_points-1)\n",
    "    minimal_horizontal_length = horizontal_lengths_reshaped.sum(dim=0).min()\n",
    "    minimal_vertical_length = vertical_lengths_reshaped.sum(dim=1).min()\n",
    "edge = torch.min(minimal_horizontal_length,minimal_vertical_length)\n",
    "edge = edge.cpu()\n",
    "print(\"edge length:\", edge.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded grid plotting in 3d. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "def plot_triang(embedded_grid,additional_comment='',savefig=False, plot_number=0,lambda_curv = None,\n",
    "                zmax = 0.5,zmin = -0.5, view_angle_horizontal = 0., view_angle_vertical = 30):\n",
    "    # triple\n",
    "    embedded_grid = embedded_grid.cpu().detach()\n",
    "    x = embedded_grid[:,:,0].flatten()\n",
    "    y = embedded_grid[:,:,1].flatten()\n",
    "    z = embedded_grid[:,:,2].flatten()\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10),dpi=300)\n",
    "    # Plot the surface.  The triangles in parameter space determine which x, y, z\n",
    "    # points are connected by an edge.\n",
    "\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "    if lambda_curv == None:\n",
    "        lambda_curv = \"?\"\n",
    "    ax.set_title(rf\"3d embedding of a grid on torus with $\\lambda_{{\\mathrm{{curv}}}} = ${lambda_curv}.\"+\n",
    "                    additional_comment)\n",
    "    \n",
    "    p = ax.plot_trisurf(x, y, z, triangles=tri.triangles, cmap=cm.Spectral,vmax=z.max(),vmin=z.min())\n",
    "    ax.set_zlim(zmin, zmax)\n",
    "    ax.view_init(view_angle_horizontal, view_angle_vertical)\n",
    "\n",
    "    # Add ticks for x, y, z\n",
    "    xticks = np.linspace(x.min(), x.max(), 3)\n",
    "    yticks = np.linspace(y.min(), y.max(), 3)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_zticks([z.min(), 0., z.max()])\n",
    "\n",
    "    ax.set_xticklabels([f\"{val:.1f}\" for val in xticks])\n",
    "    ax.set_yticklabels([f\"{val:.1f}\" for val in yticks])\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = fig.colorbar(p,shrink = 0.1)\n",
    "    cbar.set_label(\"Height\")\n",
    "    cbar.set_ticks(ticks=[z.min(), 0., z.max()])\n",
    "    cbar.set_ticklabels(ticklabels=[f'{z.min():.3f}','0', f'{z.max():.3f}'])\n",
    "\n",
    "    if savefig == True:\n",
    "        plt.savefig(Path_pictures+f\"/3dembedding_plot_{plot_number}.pdf\",format=\"pdf\")\n",
    "\n",
    "    plt.show()\n",
    "    return tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quasi_isometric_embedding(epoch, params, embedded_grid, horizontal_lengths_reshaped, vertical_lengths_reshaped, num_iter=1, \n",
    "                         mode=\"diagnostic\", loss_history=None, learning_rate=1e+1, lambda_curv = lambda_curv):\n",
    "    \"\"\"\n",
    "    Optimize a 3D embedding of a grid on a manifold so that the embedding is as isometric as possible (w.r.t geodesic distance on the manifold).\n",
    "\n",
    "    Adjusts the given embedding parameters so that the pairwise\n",
    "    distances between adjacent grid points match the provided target \n",
    "    horizontal and vertical lengths. The optimization is performed using \n",
    "    stochastic gradient descent.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): Current training epoch (used for plotting diagnostics).\n",
    "        params (iterable): Learnable parameters (coordinates of the embeddings of the grid nodes) (PyTorch tensors) to optimize.\n",
    "        embedded_grid (torch.Tensor): Initial embedding grid of shape (m, n, d),\n",
    "            where m,n are grid dimensions and d is embedding dimension (=3).\n",
    "        horizontal_lengths_reshaped (torch.Tensor): Target(geodesic) horizontal distances.\n",
    "        vertical_lengths_reshaped (torch.Tensor): Target(geodesic) vertical distances.\n",
    "        num_iter (int, optional): Number of optimization iterations to run. \n",
    "            Default is 1.\n",
    "        mode (str, optional): If \"diagnostic\", prints loss and plots progress. \n",
    "            Otherwise runs silently. Default is \"diagnostic\".\n",
    "        loss_history (list, optional): List for storing loss values across calls.\n",
    "            If None, a new list will be created.\n",
    "        learning_rate (float, optional): Learning rate for SGD optimizer. \n",
    "            Default is 1e+1.\n",
    "\n",
    "    Returns:\n",
    "        list: Updated `loss_history` containing loss values for each iteration.\n",
    "    \"\"\"\n",
    "    if loss_history is None:\n",
    "        loss_history = []  # List to store loss values\n",
    "\n",
    "    # Use an optimizer (e.g., Adam)\n",
    "    optimizer = torch.optim.SGD(params, lr=learning_rate)\n",
    "\n",
    "    for iter_num in range(num_iter):\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "        # Calculate Euclidean horizontal and vertical distances\n",
    "        horizontal_grid_distances = (embedded_grid[1:, :, :] - embedded_grid[:-1, :, :]).norm(dim=-1)\n",
    "        vertical_grid_distances = (embedded_grid[:, 1:, :] - embedded_grid[:, :-1, :]).norm(dim=-1)\n",
    "\n",
    "        # Compute the losses\n",
    "        loss_horizontal = (horizontal_lengths_reshaped - horizontal_grid_distances).square().mean()\n",
    "        loss_vertical = (vertical_lengths_reshaped - vertical_grid_distances).square().mean()\n",
    "\n",
    "        # Sum the losses\n",
    "        loss = 1e2 * (loss_horizontal + loss_vertical)\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the loss value\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        \n",
    "        # Print diagnostics if needed\n",
    "        if mode == \"diagnostic\":\n",
    "            print(f\"Iteration #{iter_num + 1}, loss: {loss.item():.3f}\")\n",
    "        \n",
    "\n",
    "    # Plot the loss values if in diagnostic mode\n",
    "    if mode == \"diagnostic\":\n",
    "        plot_triang(embedded_grid, plot_number=epoch+1,savefig=False,\n",
    "                              additional_comment=f'\\n After {len(loss_history)} iterations.', \n",
    "                              lambda_curv=lambda_curv)\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_history, label='Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the initial grid embedding\n",
    "with torch.no_grad():\n",
    "    stretched_grid = grid*edge/x_size\n",
    "stretched_grid = stretched_grid.to(optimization_device)\n",
    "#setteing small vertical perturbation\n",
    "torch.manual_seed(666)\n",
    "eps = 1e-2*edge/num_points\n",
    "z_perturbation = eps * torch.randn(num_points,num_points,1, device=optimization_device)\n",
    "\n",
    "# initiate optimization\n",
    "embedded_grid = torch.cat((stretched_grid, z_perturbation),dim=2).requires_grad_()\n",
    "\n",
    "# Define parameters (for example, weights to optimize)\n",
    "params = [embedded_grid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 \n",
    "loss_history = []\n",
    "learing_rate_embedding = 1e-2\n",
    "#embedded_grid.plot_triang()\n",
    "for epoch in range(num_epochs):\n",
    "    # Run the training loop\n",
    "    loss_history = Quasi_isometric_embedding(epoch, params, embedded_grid, horizontal_lengths_reshaped, \n",
    "                         vertical_lengths_reshaped,loss_history=loss_history, \n",
    "                         num_iter=100, mode=\"diagnostic\",learning_rate=learing_rate_embedding)\n",
    "    #embedded_grid.plot_triang(plot_number=epoch+1,savefig=True,\n",
    "    #                          additional_comment=f'\\n After {len(loss_history)} iterations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(loss_history, label='Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "if violent_saving == True:\n",
    "    plt.savefig(Path_pictures+\"/3dembedding_optimization_history/loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_grid = embedded_grid.detach()\n",
    "# grid saving\n",
    "if violent_saving == True:\n",
    "    torch.save(optimized_grid,Path_pictures+f\"/embedded_grid_{pretrained_AE_setting_name}.pt\")\n",
    "plot_triang(embedded_grid, plot_number=\"final\",savefig=True,\n",
    "                              additional_comment=f'\\n After {len(loss_history)} iterations.', lambda_curv=lambda_curv)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Plotting the embedded grid with trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "optimized_grid = optimized_grid.cpu()\n",
    "# Create the trimesh object directly from vertices and faces\n",
    "mesh = trimesh.Trimesh(vertices=optimized_grid.reshape(-1,3), faces=tri.triangles)\n",
    "\n",
    "# Extract z-coordinates of the vertices\n",
    "z_coords = mesh.vertices[:, 2]\n",
    "\n",
    "# Normalize the z-coordinates to the range [0, 1]\n",
    "z_min = z_coords.min()\n",
    "z_max = z_coords.max()\n",
    "normalized_z = (z_coords - z_min) / (z_max - z_min)\n",
    "\n",
    "# Get a colormap from matplotlib\n",
    "colormap = matplotlib.colormaps.get_cmap(\"jet\")\n",
    "#colormap = cm.get_cmap('rainbow')\n",
    "\n",
    "# Map the normalized z-coordinates to colors using the colormap\n",
    "colors = colormap(normalized_z)\n",
    "\n",
    "# Convert colors to 0-255 range and RGBA format\n",
    "vertex_colors = (colors[:, :4] * 255).astype(np.uint8)\n",
    "\n",
    "# Assign these colors to the mesh's vertices\n",
    "mesh.visual.vertex_colors = vertex_colors\n",
    "\n",
    "# Create a scene with the mesh\n",
    "scene = trimesh.Scene(mesh)\n",
    "\n",
    "# Define the initial camera transformation matrix\n",
    "# Here, we are setting the camera to look at the mesh from a specific angle\n",
    "# and zoom out by translating the camera along the y-axis\n",
    "zoom_out_factor = 12.0  # Increase this value to zoom out more\n",
    "camera_transform = trimesh.transformations.translation_matrix([-0.2, -zoom_out_factor, -5.5])\n",
    "\n",
    "\n",
    "# Set the camera transform in the scene\n",
    "scene.camera_transform = camera_transform\n",
    "\n",
    "# Display the mesh in a viewer window with the specified initial observation angle\n",
    "scene.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
