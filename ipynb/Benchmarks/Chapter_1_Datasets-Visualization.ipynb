{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Umap installation required. Type: 'pip install umap-learn'.\n",
    "\n",
    "This notebook visualises the Synthetic Gaussians, Swissroll and MNIST datasets.\n",
    "Embedding into a pre-trained AE latent space to standard dimensionality reduction techniques such as:\n",
    "\n",
    "0) PCA https://pytorch.org/docs/stable/generated/torch.pca_lowrank.html\n",
    "1) LLE https://cs.nyu.edu/~roweis/lle/papers/lleintroa4.pdf\n",
    "2) t-SNE https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\n",
    "3) UMAP https://umap-learn.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import ricci_regularization\n",
    "import yaml, os\n",
    "import sklearn # for t-SNE and LLE\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_pictures = \"../../plots/datasets_visualization\"\n",
    "violent_saving = True\n",
    "opacity = 0.5 # point opacity on plots\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(Path_pictures):\n",
    "    os.makedirs(Path_pictures)\n",
    "    print(f\"Created folder: {Path_pictures}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {Path_pictures}\")\n",
    "print(f\"Plots will be saved to: {Path_pictures}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I. Loading datasets and AE weights to produce AE latent encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = {} # dictionary of experimental configs to load pretrained AE weights\n",
    "experiment_config[\"MNIST\"] = '../../experiments/MNIST_Setting_1_config.yaml'\n",
    "experiment_config[\"Synthetic\"] = '../../experiments/Synthetic_Setting_1_config.yaml'\n",
    "experiment_config[\"Swissroll\"] = '../../experiments/Swissroll_Setting_1_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = {} # dictionary to keep all visualizations\n",
    "dataset_names = [\"MNIST\",\"Swissroll\",\"Synthetic\"]\n",
    "# loading test dataset, its encoding and labels for each dataset\n",
    "for dataset_name in dataset_names:\n",
    "    with open( experiment_config[dataset_name], 'r') as yaml_file:\n",
    "        yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "    # Load data loaders based on YAML configuration\n",
    "    dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "        datasets_root= '../../datasets/',\n",
    "        dataset_config=yaml_config[\"dataset\"],\n",
    "        data_loader_config=yaml_config[\"data_loader_settings\"], \n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    #train_loader = dict[\"train_loader\"]\n",
    "    test_loader = dict[\"test_loader\"]\n",
    "    print(\"Data loaders created successfully.\")\n",
    "    torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path=\"../\", verbose=False)\n",
    "    print(\"AE weights loaded successfully from\", Path_ae_weights)\n",
    "    torus_ae.cpu()\n",
    "    print(f\"AE moved to {next(torus_ae.parameters()).device}\")\n",
    "    # add input_dataset (as a single tensor), AE_latent_encoding and labels to visualization\n",
    "    visualization[dataset_name] = ricci_regularization.DataLoaders.get_dataset_and_encoding_from_dataloader(\n",
    "        test_loader,\n",
    "        torus_ae.encoder_to_lifting,\n",
    "        input_dim=yaml_config[\"architecture\"][\"input_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Standard embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    input_dataset = visualization[dataset_name][\"input_dataset\"]\n",
    "    #PCA\n",
    "    visualization[dataset_name][\"PCA\"],s,v = torch.pca_lowrank(input_dataset,q=2)\n",
    "    #LLE\n",
    "    visualization[dataset_name][\"LLE\"], _ = sklearn.manifold.locally_linear_embedding(input_dataset, n_neighbors=12, n_components=2,eigen_solver='arpack')\n",
    "    #t-SNE\n",
    "    visualization[dataset_name][\"TSNE\"] = sklearn.manifold.TSNE(n_components=2, perplexity=30, random_state=0).fit_transform(input_dataset)\n",
    "    #UMAP\n",
    "    mapper = umap.UMAP().fit(input_dataset)\n",
    "    visualization[dataset_name][\"UMAP\"] = mapper.embedding_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    for visualization_method in [\"PCA\",\"LLE\",\"TSNE\",\"UMAP\",\"AE_latent_encoding\"]:\n",
    "        ricci_regularization.PlottingTools.plot_2d_encoding(\n",
    "            encoded_points=visualization[dataset_name][visualization_method],\n",
    "            color_labels=visualization[dataset_name][\"labels\"],\n",
    "            cmap=\"jet\",\n",
    "            opacity=opacity,\n",
    "            Saving_file_name=f'{Path_pictures}/{dataset_name}_{visualization_method}.pdf',\n",
    "            verbose=False,\n",
    "            save_plot=violent_saving\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
